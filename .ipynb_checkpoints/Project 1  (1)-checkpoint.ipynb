{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 1 project: Crime Data in Denver for 2015-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'census'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4a08c5b40f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#dependencies for location heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcensus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCensus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcensus_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgmaps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'census'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from datetime import datetime as dt \n",
    "import random\n",
    "import matplotlib.colors\n",
    "from pylab import rcParams\n",
    "\n",
    "#dependencies for location heatmap \n",
    "from census import Census \n",
    "from config import (census_key, gkey)\n",
    "import gmaps \n",
    "import requests \n",
    "import time \n",
    "\n",
    "#Census API Key \n",
    "c = Census(census_key, year = 2015) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing crime data and offense code csv files and merging them on offense code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import crime.csv file \n",
    "#import crime.csv file\n",
    "df_crime = pd.read_csv('crimedata.csv')\n",
    "df_offense = pd.read_csv('offense_codes.csv')\n",
    "# Group OFFENSE_CODEs by OFFENSE_CATEGORY_ID\n",
    "df_offense = df_offense.drop_duplicates(subset=['OFFENSE_CODE','OFFENSE_CATEGORY_ID'])\n",
    "\n",
    "df_crimemerge = df_crime.merge(df_offense, on='OFFENSE_CODE')\n",
    "\n",
    "df_crimemerge.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crimemerge['GEO_LON'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting date object to a date time date type and refining our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'FIRST_OCCURRENCE_DATE','LAST_OCCURRENCE_DATE','REPORTED_DATE' from object to datetime:\n",
    "df_crimemerge[['FIRST_OCCURRENCE_DATE','LAST_OCCURRENCE_DATE','REPORTED_DATE']] = df_crimemerge[['FIRST_OCCURRENCE_DATE','LAST_OCCURRENCE_DATE','REPORTED_DATE']].apply(pd.to_datetime)\n",
    "df_crimemerge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining new data set by keeping only the columns we are plotting against:\n",
    "df_crimemerge_refined = df_crimemerge.loc[:,[\"INCIDENT_ID\",\"OFFENSE_ID\",\"OFFENSE_CODE\",\"OFFENSE_TYPE_ID_x\",\"OFFENSE_CATEGORY_ID_x\",\"FIRST_OCCURRENCE_DATE\",\"REPORTED_DATE\",\"INCIDENT_ADDRESS\",\"GEO_LON\",\"GEO_LAT\",\"DISTRICT_ID\",\"PRECINCT_ID\",\"NEIGHBORHOOD_ID\",\"IS_CRIME_x\",\"IS_TRAFFIC_x\",\"OFFENSE_CATEGORY_NAME\"]]\n",
    "df_crimemerge_refined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renamimg comlumns with _x:\n",
    "df_crimemerge_refined = df_crimemerge_refined.rename(index=str , columns={\"OFFENSE_TYPE_ID_x\" : \"OFFENSE_TYPE_ID\" , \"OFFENSE_CATEGORY_ID_x\" : \"OFFENSE_CATEGORY_ID\"})\n",
    "df_crimemerge_refined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping all missing values for Longitude and Latitude:\n",
    "df_crimemerge_refined[\"GEO_LON\"].replace('', np.nan, inplace=True)\n",
    "df_crimemerge_refined.dropna(subset=[\"GEO_LON\"], inplace=True)\n",
    "\n",
    "df_crimemerge_refined[\"GEO_LAT\"].replace('', np.nan, inplace=True)\n",
    "df_crimemerge_refined.dropna(subset=[\"GEO_LAT\"], inplace=True)\n",
    "\n",
    "df_crimemerge_refined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crimemerge_refined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_crimemerge_refined = df_crimemerge_refined['OFFENSE_CATEGORY_ID'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our bins for each year 2015-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2015 bin\n",
    "df_15 = df_crimemerge_refined.loc[df_crimemerge_refined[str('FIRST_OCCURRENCE_DATE')] < '1/1/16 0:00']\n",
    "df_15.count()\n",
    "df_15['FIRST_OCCURRENCE_DATE'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016 bin\n",
    "df_16 = df_crimemerge_refined.loc[(df_crimemerge_refined[str('FIRST_OCCURRENCE_DATE')] > '12/31/15 23:59') & (df_crimemerge_refined[str('FIRST_OCCURRENCE_DATE')] < '1/1/17 0:00')]\n",
    "df_16.count()\n",
    "df_16['FIRST_OCCURRENCE_DATE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017 bin\n",
    "df_17 = df_crimemerge_refined.loc[df_crimemerge_refined[str('FIRST_OCCURRENCE_DATE')] > '12/31/16 23:59']\n",
    "df_17.count()\n",
    "df_17['FIRST_OCCURRENCE_DATE'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Plot: Number of offenses by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offense_categories = df_crimemerge_refined.groupby('OFFENSE_CATEGORY_ID')\n",
    "# offense_categories_count = offense_categories.count().astype(str)\n",
    "#type(offense_categories)\n",
    "offense_categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offense_counts = df_crimemerge_refined['OFFENSE_CATEGORY_ID'].value_counts(dropna=True, sort=True)\n",
    "offense_counts.head()\n",
    "df_offense = offense_counts.rename_axis('Offense Type').reset_index(name='counts')\n",
    "df_offense['Offense Type'].count()\n",
    "\n",
    "#plot graph\n",
    "colors = ['blue', 'red', 'green', 'yellow', 'brown', 'orange', 'grey', 'purple', 'black', 'lightblue', 'gold', 'violet', 'pink', 'maroon']\n",
    "# Creating our first plot: Count of offence type for all years\n",
    "# plt.figure();\n",
    "\n",
    "# offense_catgories.plot.hist()\n",
    "# set categories as x-axis\n",
    "x_axis = df_offense[\"Offense Type\"]\n",
    "# add tick mark for every offense type\n",
    "tick_offense = [value for value in x_axis]\n",
    "\n",
    "#plot graph\n",
    "plt.figure(figsize=(20,3))\n",
    "plt.bar(x_axis, df_offense['counts'], color=colors, alpha=0.9, align='center')\n",
    "plt.xticks(tick_offense, df_offense['Offense Type'], rotation=\"vertical\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neighbor = offense_counts.rename_axis('Offense Types').reset_index(name='counts')\n",
    "df_neighbor['Offense Types'].count()\n",
    "# Labels for the sections of our pie chart\n",
    "labels = df_neighbor[\"Offense Types\"]\n",
    "\n",
    "# The values of each section of the pie chart\n",
    "sizes = df_neighbor[\"counts\"]\n",
    "\n",
    "# The colors of each section of the pie chart\n",
    "colors = [\"red\", \"orange\", \"lightcoral\", \"lightskyblue\", \"Purple\"]\n",
    "\n",
    "# Tells matplotlib to seperate the \"Python\" section from the others\n",
    "explode = (0, 0, 0, 0,0,0, 0, 0, 0,0.6,0.6, 0.6, 0.6, 0)\n",
    "\n",
    "# Creates the pie chart based upon the values above\n",
    "# Automatically finds the percentages of each part of the pie chart\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=None,\n",
    "       autopct=\"%1.1f%%\", shadow=False, startangle=0)\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 15\n",
    "\n",
    "# Tells matplotlib that we want a pie chart with equal axes\n",
    "plt.axis(\"equal\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Plot: Number of offenses by time of day fro each observed year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data for each our for each year\n",
    "\n",
    "#Year 2015\n",
    "hour_2015 = df_15['FIRST_OCCURRENCE_DATE'].dt.hour\n",
    "hour_2015_count = hour_2015.value_counts()\n",
    "#Time of day for 2015\n",
    "morning_2015 = hour_2015_count[0]+hour_2015_count[1]+hour_2015_count[2]+hour_2015_count[3]+hour_2015_count[4]+hour_2015_count[5]+hour_2015_count[6]+hour_2015_count[7]+hour_2015_count[8]\n",
    "afternoon_2015 = hour_2015_count[9]+hour_2015_count[10]+hour_2015_count[11]+hour_2015_count[12]+hour_2015_count[13]+hour_2015_count[14]+hour_2015_count[15]+hour_2015_count[16]\n",
    "evening_2015 = hour_2015_count[17]+hour_2015_count[18]+hour_2015_count[19]+hour_2015_count[20]+hour_2015_count[21]+hour_2015_count[22]+hour_2015_count[23]\n",
    "\n",
    "#Year 2016\n",
    "hour_2016 = df_16['FIRST_OCCURRENCE_DATE'].dt.hour\n",
    "hour_2016_count = hour_2016.value_counts()\n",
    "#Time of day for 2016\n",
    "morning_2016 = hour_2016_count[0]+hour_2016_count[1]+hour_2016_count[2]+hour_2016_count[3]+hour_2016_count[4]+hour_2016_count[5]+hour_2016_count[6]+hour_2016_count[7]+hour_2016_count[8]\n",
    "afternoon_2016 = hour_2016_count[9]+hour_2016_count[10]+hour_2016_count[11]+hour_2016_count[12]+hour_2016_count[13]+hour_2016_count[14]+hour_2016_count[15]+hour_2016_count[16]\n",
    "evening_2016 = hour_2016_count[17]+hour_2016_count[18]+hour_2016_count[19]+hour_2016_count[20]+hour_2016_count[21]+hour_2016_count[22]+hour_2016_count[23]\n",
    "\n",
    "#Year 2017\n",
    "hour_2017 = df_17['FIRST_OCCURRENCE_DATE'].dt.hour\n",
    "hour_2017_count = hour_2017.value_counts()\n",
    "#Time of day for 2017\n",
    "morning_2017 = hour_2017_count[0]+hour_2017_count[1]+hour_2017_count[2]+hour_2017_count[3]+hour_2017_count[4]+hour_2017_count[5]+hour_2017_count[6]+hour_2017_count[7]+hour_2017_count[8]\n",
    "afternoon_2017 = hour_2017_count[9]+hour_2017_count[10]+hour_2017_count[11]+hour_2017_count[12]+hour_2017_count[13]+hour_2017_count[14]+hour_2017_count[15]+hour_2017_count[16]\n",
    "evening_2017 = hour_2017_count[17]+hour_2017_count[18]+hour_2017_count[19]+hour_2017_count[20]+hour_2017_count[21]+hour_2017_count[22]+hour_2017_count[23]\n",
    "#Created a dictionary of all data\n",
    "Labels = ['2015 Morning', '2015 Afternoon','2015 Evening','2016 Morning', '2016 Afternoon','2016 Evening','2017 Morning', '2017 Afternoon','2017 Evening']\n",
    "Times = [morning_2015, afternoon_2015, evening_2015,morning_2016, afternoon_2016, evening_2016,morning_2017, afternoon_2017, evening_2017]\n",
    "hour_of_crime_dict = {'Time of Day':Labels, 'Crimes': Times}\n",
    "hour_of_crime_df = pd.DataFrame(hour_of_crime_dict)\n",
    "#x_axis = np.arange(0,len(morning_2015))\n",
    "#tick_locations='12:00am-8:00am'\n",
    "\n",
    "\n",
    "#building the dataframe\n",
    "twenty_15 = pd.DataFrame(hour_2015_count)\n",
    "twenty_16= pd.DataFrame(hour_2016_count)\n",
    "twenty_17= pd.DataFrame(hour_2017_count)\n",
    "hour_of_crime_df\n",
    "# Create our x_axis list\n",
    "x_axis = np.arange(0, 9, 1)\n",
    "# Creates a list based on the sin of our x_axis values\n",
    "y_axis = hour_of_crime_df['Crimes']\n",
    "# Plot both of these lines so that they will appear on our final chart\n",
    "plt.plot(x_axis, y_axis)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_chart = offense_categories.plot(kind='bar')\n",
    "\n",
    "# Set the xlabel and ylabel using class methods\n",
    "count_chart.set_xlabel(\"OFFENSE_TYPE_ID\")\n",
    "count_chart.set_ylabel(\"INCIDENT_ID\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up our data into groups based upon 'offonse codes'\n",
    "offense_codes = offense_categories.groupby('OFFENSE_CODE')\n",
    "\n",
    "# Find out how many offenses per each offense code \n",
    "offense_code_count = offense_codes['OFFENSE_CODE'].count()\n",
    "offense_code_count.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart our data, give it a title, and label the axes\n",
    "offense_code_count = offense_code_count.plot(kind=\"bar\", title=\"Offenses By Category\")\n",
    "offense_code_count.set_xlabel(\"Offense Codes\")\n",
    "offense_code_count.set_ylabel(\"Number of offenses\")\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = df_crimemerge_refined[\"OFFENSE_CATEGORY_ID\"]\n",
    "y_axis = df_crimemerge_refined[\"OFFENSE_CATEGORY_ID\"].count()\n",
    "\n",
    "plt.bar(x_axis, y_axis)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating plot for 2015 vs Offense Category ID\n",
    "plt.bar(x_axis_17,y_axis_17,color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the dataframe by offense category and find the most crime category occurance \n",
    "df_offense_category = df.groupby('OFFENSE_CATEGORY_ID')\n",
    "df_offense_category_count = df_offense_category.count()\n",
    "df_offense_category_count = df_offense_category_count.sort_values(by=['OFFENSE_ID'], ascending = False)\n",
    "df_offense_category_count.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the dataframe by neighborhoods and find the most crime-ridden neighborhoods  \n",
    "df_neighborhood = df.groupby('NEIGHBORHOOD_ID')\n",
    "df_neighborhood_count = df_neighborhood.count()\n",
    "df_neighborhood_count = df_neighborhood_count.sort_values(by = ['INCIDENT_ID'], ascending = False)\n",
    "df_neighborhood_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create histogram for offense catagory\n",
    "#offense_catagory = dfcrimemerge.groupby('OFFENSE_CATEGORY_ID')\n",
    "#offense_count = offense_catagory['OFFENSE_ID'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crimemerge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_crimemerge_refined['GEO_LAT'].describe())\n",
    "print(df_crimemerge_refined['GEO_LON'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "northeast_list = [] \n",
    "northwest_list = [] \n",
    "southeast_list = []\n",
    "southwest_list = []\n",
    "\n",
    "if lat in df_crimemerge_refined['GEO_LAT'] > 39.739802 and lon in df_crimemerge_refined['GEO_LON'] > -104.982737: \n",
    "    northeast_list.append[]\n",
    "    \n",
    "     \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby the mean of each neighborhood \n",
    "df_neighborhood_mean = df_crimemerge_refined.groupby('NEIGHBORHOOD_ID').mean()\n",
    "df_neighborhood_mean\n",
    "\n",
    "#Groupby the count of each neighborhood\n",
    "df_neighborhood_crime_count = df_crimemerge_refined.groupby('NEIGHBORHOOD_ID').count()\n",
    "df_neighborhood_crime_count\n",
    "\n",
    "#Merge two dataframes together \n",
    "df_neighborhood = pd.merge(df_neighborhood_mean, df_neighborhood_crime_count, on = 'NEIGHBORHOOD_ID', how = 'outer')\n",
    "\n",
    "#only select 3 columns \n",
    "df_neighborhood = df_neighborhood[['GEO_LAT_x', 'GEO_LON_x', 'INCIDENT_ID_y']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_neighborhood_crime_count.head()\n",
    "df_neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crimemerge_refined['GEO_LAT_x', GEO_LAT_x].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15_top_5 = pd.DataFrame(df_15['OFFENSE_CATEGORY_ID'][0:5].value_counts())\n",
    "df_16_top_5 = pd.DataFrame(df_16['OFFENSE_CATEGORY_ID'][0:5].value_counts())\n",
    "df_17_top_5 = pd.DataFrame(df_17['OFFENSE_CATEGORY_ID'][0:5].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Location Point Map \n",
    "locations = df_neighborhood[[\"GEO_LAT_x\", \"GEO_LON_x\"]].astype(float)\n",
    "markers = gmaps.marker_layer(locations)\n",
    "fig.add_layer(markers)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crimemerge_refined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure gmaps with API key\n",
    "gmaps.configure(api_key=gkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store 'Lat' and 'Lng' into  locations \n",
    "locations = df_neighborhood[[\"GEO_LAT_x\", \"GEO_LON_x\"]].astype(float)\n",
    "\n",
    "# Convert crime rate to float and store\n",
    "# HINT: be sure to handle NaN values\n",
    "crime_rate = df_neighborhood[\"INCIDENT_ID_y\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a poverty Heatmap layer\n",
    "fig = gmaps.figure(map_type = 'HYBRID')\n",
    "\n",
    "heat_layer = gmaps.heatmap_layer(locations, weights = crime_rate,\n",
    "                                 dissipating=True, max_intensity=2000,\n",
    "                                 point_radius = 20)\n",
    "\n",
    "# Adjust heat_layer setting to help with heatmap dissipating on zoom\n",
    "heat_layer.dissipating = True\n",
    "heat_layer.max_intensity = 2000\n",
    "heat_layer.point_radius = 20\n",
    "\n",
    "fig.add_layer(heat_layer)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crimemerge_refined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting top 5 crimes for 2015 \n",
    "df_15_top_5 = pd.DataFrame(df_15['OFFENSE_CATEGORY_ID'].value_counts())\n",
    "df_15_top_5 = df_15_top_5[0:5] \n",
    "print(df_15_top_5)\n",
    "\n",
    "#selecting top 5 crimes for 2016 \n",
    "df_16_top_5 = pd.DataFrame(df_16['OFFENSE_CATEGORY_ID'].value_counts())\n",
    "df_16_top_5 = df_16_top_5[0:5] \n",
    "print(df_16_top_5)\n",
    "\n",
    "\n",
    "#selecting top 5 crimes for 2017 \n",
    "df_17_top_5 = pd.DataFrame(df_17['OFFENSE_CATEGORY_ID'].value_counts())\n",
    "df_17_top_5 = df_17_top_5[0:5] \n",
    "print(df_17_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merger the top 5 crime data of 2015 and 2016 \n",
    "df_1516_top_5 = pd.merge(df_15_top_5, df_16_top_5, left_index=True, right_index=True)\n",
    "\n",
    "#Merger the top 5 crime data of 2015, 2016 and 2017\n",
    "df_151617_top_5 = pd.merge(df_1516_top_5, df_17_top_5, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting values over years for each crime type\n",
    "y1 = [23305, 23738, 24242]\n",
    "y2 = [15784, 15784, 17260]\n",
    "y3 = [14161, 14161, 14649]\n",
    "y4 = [9791, 9914, 9344]\n",
    "y5 = [6262, 6568, 7333]\n",
    "\n",
    "x = np.arange(len(y1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot data with multiple bar graphs side by side \n",
    "\n",
    "bar_width = 0.15\n",
    "plt.bar(x, y1, width = bar_width)\n",
    "plt.bar(x + bar_width , y2, width = bar_width)\n",
    "plt.bar(x + bar_width*2, y3, width = bar_width)\n",
    "plt.bar(x + bar_width*3, y4, width = bar_width)\n",
    "plt.bar(x + bar_width*4, y5, width = bar_width)\n",
    "plt.xticks(np.arange(3), ('2015', '2016', '2017'))\n",
    "plt.legend(['traffic-accident', 'all-other-crimes', 'larceny', 'public-disorder', 'theft-from-motor-vehicle'], title = 'Crime Types')\n",
    "plt.xlabel ('Year')\n",
    "plt.ylabel ('Crime Count')\n",
    "plt.title('Top 5 Crime Types over Years')\n",
    "rcParams['figure.figsize'] = 10, 10\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
